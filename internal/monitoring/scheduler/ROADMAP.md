# Roadmap: RefactorizaciÃ³n del Scheduler (Scalable & Async)

Este documento define el plan para transformar el Scheduler actual ("todÃ³logo" y sÃ­ncrono) en un sistema robusto, concurrente y desacoplado.

## Objetivos
1.  **Concurrencia**: Procesar mÃºltiples targets en paralelo (Worker Pool).
2.  **Desacoplamiento**: Separar la ejecuciÃ³n del check, el anÃ¡lisis de resultados y las notificaciones.
3.  **AsincronÃ­a**: Las notificaciones NO deben bloquear el proceso de monitoreo.
4.  **Limpieza**: Eliminar la lÃ³gica monolÃ­tica y usar la nueva arquitectura de Alertas (`AlertEvent`).

---

## Fase 1: DescomposiciÃ³n de Responsabilidades (SRP) (âœ… Completado)

Actualmente el `Scheduler` hace todo. Vamos a dividirlo en componentes especializados:

- [x] **`HealthChecker`**:
    - Responsabilidad: Ejecutar la lÃ³gica de "Ping hasta estabilidad" (los 12 intentos).
    - Input: `MonitoringTarget`.
    - Output: `CheckSessionResult` (Raw results, pings count).
    - *Nota*: No decide si es UP/DOWN, solo recopila datos.

- [x] **`MetricsCalculator`**:
    - Responsabilidad: Calcular estadÃ­sticas de la sesiÃ³n actual y actualizar histÃ³ricos.
    - Capacidades:
        - Actual: Promedio (Avg) **(Solo considera estados UP para no ensuciar la lÃ­nea base)**, MaxResponseTime.
        - HistÃ³rico: Actualizar promedios mÃ³viles (EMA 7 dÃ­as), contadores de uptime/downtime.
    - Input: `CheckSessionResult`.
    - Output: `SessionMetrics` (Struct con los valores calculados).

- [x] **`ResultAnalyzer` (o `Evaluator`)**:
    - Responsabilidad: Determinar el estado final (`UP`, `DOWN`, `DEGRADED`, `FLAPPING`, `UNSTABLE`).
    - LÃ³gica:
        - 3 consecutivos = Estable.
        - Tiempo > 2x Promedio HistÃ³rico = Degraded.
        - 5-9 intentos = Unstable.
        - >12 intentos = Flapping.
    - Input: `CheckSessionResult`, `SessionMetrics`, `HistoricalStats`.
    - Output: `TargetStatus` (Nuevo estado).

- [x] **`StateUpdater`**:
    - Responsabilidad: Actualizar la entidad `MonitoringTarget` (Status, LastCheckedAt, LastResponseTime) en memoria y base de datos.
    - *Nota*: Esto es crucial para que el Dashboard muestre el estado actual inmediato, independiente del historial de eventos.

- [ ] **`NotificationDispatcher`**:
    - Responsabilidad: Enviar alertas de forma asÃ­ncrona.
    - Estado: Estructura creada, falta integraciÃ³n con el mÃ³dulo de `notifications`.

## Fase 2: ImplementaciÃ³n del Worker Pool (âœ… Completado / En ValidaciÃ³n)

El scheduler no debe iterar uno por uno. Debe despachar trabajo.

- [x] **DiseÃ±ar `WorkerPool` (`Orchestrator`)**:
    - Implementado en `orchestrator.go`.
    - Configurable: `NumWorkers`.
    - Job Queue: `chan *MonitoringTarget`.
- [x] **Refactorizar `Scheduler.Start()`**:
    - Implementado el ciclo de vida en `Orchestrator`.
    - 1. Iniciar Workers.
    - 2. Enviar targets al Job Queue.
    - 3. Esperar finalizaciÃ³n (WaitGroup).

## Fase 2.5: SimulaciÃ³n y VerificaciÃ³n (âœ… Completado)

Antes de integrar con la DB real, verificamos la lÃ³gica con un simulador.

- [x] **Simulador (`simulator/main.go`)**:
    - Implementado con **Peticiones HTTP Reales** (Google, HttpBin).
    - Escenarios probados: Stable UP, Stable DOWN (500), Degraded (Delay > 2x HistÃ³rico).
    - VerificaciÃ³n de MÃ©tricas: Confirmado que el promedio ignora fallos y estados degradados.

## Fase 3: IntegraciÃ³n de Notificaciones AsÃ­ncronas (ðŸš§ Pendiente)

Las notificaciones son I/O bound y lentas (HTTP requests a Telegram/Slack). No pueden frenar el monitoreo.

- [ ] **Conectar `Orchestrator` con `NotificationDispatcher`**:
    - El orquestador debe pasar el resultado del anÃ¡lisis al dispatcher.
- [ ] **Implementar `NotificationWorker`**:
    - Goroutine que escucha `alertChannel`.
    - Llama al `NotificationService` (que usarÃ¡ los Adapters de Telegram/Slack).
- [ ] **Integrar `SeverityMapper`**:
    - El `ResultAnalyzer` usarÃ¡ el `SeverityMapper` para convertir el cambio de estado en un `AlertEvent`.
    - Si `ShouldNotify()` es true, se envÃ­a al canal.

## Fase 4: Persistencia y MÃ©tricas (ðŸš§ Pendiente)

- [ ] **Optimizar Escrituras**:
    - Evaluar si guardar cada check o solo los cambios de estado/mÃ©tricas agregadas.
    - Mover la persistencia (`saveToSQL`, `updateStatistics`) fuera del loop crÃ­tico del worker si es posible (o hacerlo eficiente).
- [ ] **Conectar Repositorios Reales**:
    - Reemplazar `InMemoryTargetRepo` del simulador por `PostgresTargetRepository`.

## Fase 5: Limpieza y MigraciÃ³n

- [ ] **Eliminar `Scheduler` monolÃ­tico**: Reemplazar por la versiÃ³n orquestadora.
- [ ] **Borrar cÃ³digo legacy**: Eliminar `alert_message.go` y los `fmt.Print` directos.
- [ ] **ConfiguraciÃ³n**: Permitir inyectar el tamaÃ±o del pool y timeouts desde configuraciÃ³n.

---

## Diagrama de Flujo Propuesto

```mermaid
graph TD
    A[Scheduler Orchestrator] -->|Push Target| B(Job Queue)
    B --> C[Worker 1]
    B --> D[Worker 2]
    B --> E[Worker N]
    
    C -->|Execute| F[HealthChecker]
    F -->|Raw Results| M[MetricsCalculator]
    M -->|Metrics| G[ResultAnalyzer]
    F -->|Raw Results| G
    
    G -->|State Change?| H{Yes}
    H --> H1[Update Target Status DB]
    H1 --> I[Save Event History DB]
    I --> J{Severity Changed?}
    J -- Yes --> K[AlertEvent -> AlertChannel]
    J -- No --> L[No Notification]
    
    G -->|No| O[Update Target LastChecked]
    O --> P2[Save Metrics Only]
    
    K --> Q[Notification Worker]
    Q -->|Async| R[Telegram/Slack API]
```
